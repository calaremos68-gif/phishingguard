import streamlit as st
import re
from textblob import TextBlob
from transformers import pipeline

# --- CARGAR DETECTOR DE IA (Hugging Face) ---
@st.cache_resource
def load_detector():
    return pipeline("text-classification", model="openai-community/gpt2", truncation=True, max_length=512)

detector_ia = load_detector()

# --- FUNCIÃ“N DE ANÃLISIS SIN SPACY ---
def analizar_texto(texto):
    if not texto.strip():
        return {"error": "Por favor ingresa un texto."}

    alertas = []

    # 1. URLs sospechosas
    urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', texto)
    for url in urls:
        dominio = url.split("//")[-1].split("/")[0]
        if any(ext in dominio.lower() for ext in ["login", "verify", "secure", "update", "account", "bank", "paypal"]) and \
           not any(valid in dominio.lower() for valid in ["google.com", "facebook.com", "amazon.com", "youtube.com", "instagram.com"]):
            alertas.append(f"ğŸš¨ URL sospechosa: {url}")

    # 2. Sentimiento (TextBlob) â€” NO NECESITA MODELO DESCARGABLE
    blob = TextBlob(texto)
    polaridad = blob.sentiment.polarity
    subjetividad = blob.sentiment.subjectivity
    if polaridad > 0.6 or polaridad < -0.3:
        alertas.append(f"âš ï¸ Tono extremo: {'Muy positivo' if polaridad > 0.6 else 'Muy negativo'} ({polaridad:.2f})")

    # 3. Palabras de urgencia
    urgencias = ["urgente", "inmediato", "ahora", "24h", "cerrar", "bloquear", "verificar", "confirmar", "sin delay", "sin acciÃ³n"]
    palabras_urgencia = [p for p in urgencias if p in texto.lower()]
    if len(palabras_urgencia) >= 2:
        alertas.append(f"âš ï¸ Palabras de urgencia: {', '.join(palabras_urgencia)}")

    # 4. Frases demasiado largas/formales (basado en longitud de oraciones)
    oraciones = texto.split('.')
    frases_largas = sum(1 for oracion in oraciones if len(oracion.split()) > 15)
    if frases_largas > 1:
        alertas.append("âš ï¸ Demasiadas frases largas y formales â€” poco natural para un humano")

    # 5. DetecciÃ³n de IA (Hugging Face)
    try:
        ia_pred = detector_ia(texto[:512])
        if ia_pred[0]['label'] == 'LABEL_1' and ia_pred[0]['score'] > 0.7:
            alertas.append("ğŸš¨ ALTA PROBABILIDAD DE SER GENERADO POR IA (como WormGPT)")
    except Exception:
        alertas.append("â„¹ï¸ No se pudo analizar con IA (texto muy largo o error tÃ©cnico)")

    # Calcular nivel de riesgo
    score = len(alertas)
    if score >= 4:
        nivel = "ğŸ”´ ALTO RIESGO â€” Â¡Es probable phishing generado por IA!"
        color = "red"
    elif score >= 2:
        nivel = "ğŸŸ¡ MODERADO RIESGO â€” Revisa con cuidado"
        color = "orange"
    else:
        nivel = "ğŸŸ¢ BAJO RIESGO â€” Parece legÃ­timo"
        color = "green"

    return {
        "nivel": nivel,
        "color": color,
        "alertas": alertas,
        "score": score
    }

# --- INTERFAZ STREAMLIT ---
st.set_page_config(page_title="ğŸ›¡ï¸ PhishingGuard", page_icon="ğŸ›¡ï¸", layout="centered")

# --- LOGO ---
st.image("https://i.ibb.co/8YqKJQk/phishingguard-logo.png", width=180)

st.title("ğŸ›¡ï¸ PhishingGuard â€” Detecta mensajes de phishing generados por IA")
st.markdown("""
*Â¿Recibiste un mensaje extraÃ±o? PÃ©galo aquÃ­ y te diremos si fue creado por una IA maliciosa como WormGPT.*  
*(No necesitas ser experto â€” solo pega y presiona "Analizar")*
""")

# Entrada de texto
texto_input = st.text_area(
    "Pega aquÃ­ el mensaje que quieres analizar:",
    height=200,
    placeholder="Ejemplo: 'Estimado cliente, su cuenta serÃ¡ bloqueada en 2 horas. Haga clic aquÃ­: https://secure-bank-login.xyz'"
)

# BotÃ³n de anÃ¡lisis
if st.button("ğŸ” Analizar mensaje"):
    if texto_input.strip():
        with st.spinner("Analizando... Esto puede tomar unos segundos"):
            resultado = analizar_texto(texto_input)
        
        if "error" in resultado:
            st.error(resultado["error"])
        else:
            st.markdown(f"### {resultado['nivel']}")
            st.markdown(f"<span style='color:{resultado['color']}; font-weight:bold;'>{resultado['nivel']}</span>", unsafe_allow_html=True)
            
            if resultado["alertas"]:
                st.subheader("ğŸ“Œ SeÃ±ales detectadas:")
                for alerta in resultado["alertas"]:
                    st.warning(alerta)
            else:
                st.success("âœ… No se encontraron seÃ±ales de riesgo.")
    else:
        st.warning("Por favor ingresa un texto para analizar.")

# InformaciÃ³n adicional
st.markdown("---")
st.markdown("""
### â„¹ï¸ Â¿QuÃ© es esto?
PhishingGuard es una herramienta educativa creada para ayudarte a identificar mensajes falsos generados por inteligencia artificial maliciosa (como **WormGPT**).  
**No es 100% perfecta**, pero detecta patrones comunes usados por ciberdelincuentes.

> âŒ Nunca hagas clic en enlaces sospechosos.  
> âœ… Si dudas, contacta directamente a la empresa por su sitio oficial.

### ğŸ“š Â¿Quieres aprender mÃ¡s?
- [Curso de Ciberseguridad Cisco (gratis)](https://www.netacad.com/courses/cybersecurity)
- [Hugging Face - Modelos de IA Ã©ticos](https://huggingface.co/models)
""")

# Pie de pÃ¡gina
st.markdown("<small>ğŸ› ï¸ Hecho con â¤ï¸ usando Python + Streamlit. No al uso malicioso de la IA.</small>", unsafe_allow_html=True)
