import streamlit as st
import re
from textblob import TextBlob
import spacy
import subprocess
import sys
from transformers import pipeline

# --- DESCARGA AUTOMÃTICA DEL MODELO DE SPACY ---
@st.cache_resource
def load_spacy_model():
    try:
        nlp = spacy.load("es_core_news_sm")
        return nlp
    except OSError:
        st.info("ğŸ“¥ Descargando modelo de espaÃ±ol 'es_core_news_sm'... Esto puede tomar 1-2 minutos.")
        subprocess.check_call([sys.executable, "-m", "spacy", "download", "es_core_news_sm"])
        nlp = spacy.load("es_core_news_sm")
        st.success("âœ… Modelo de espaÃ±ol descargado correctamente.")
        return nlp

nlp = load_spacy_model()

# Cargar detector de IA (modelo genÃ©rico de Hugging Face)
@st.cache_resource
def load_detector():
    return pipeline("text-classification", model="openai-community/gpt2", truncation=True, max_length=512)

detector_ia = load_detector()

# FunciÃ³n de anÃ¡lisis
def analizar_texto(texto):
    if not texto.strip():
        return {"error": "Por favor ingresa un texto."}

    resultados = {}
    alertas = []

    # 1. URLs sospechosas
    urls = re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', texto)
    resultados['urls'] = urls
    for url in urls:
        dominio = url.split("//")[-1].split("/")[0]
        if any(ext in dominio.lower() for ext in ["login", "verify", "secure", "update", "account", "bank", "paypal"]) and \
           not any(valid in dominio.lower() for valid in ["google.com", "facebook.com", "amazon.com", "youtube.com", "instagram.com"]):
            alertas.append(f"ğŸš¨ URL sospechosa: {url}")

    # 2. Sentimiento (TextBlob)
    blob = TextBlob(texto)
    polaridad = blob.sentiment.polarity
    subjetividad = blob.sentiment.subjectivity
    if polaridad > 0.6 or polaridad < -0.3:
        alertas.append(f"âš ï¸ Tono extremo: {'Muy positivo' if polaridad > 0.6 else 'Muy negativo'} ({polaridad:.2f})")

    # 3. Palabras de urgencia
    urgencias = ["urgente", "inmediato", "ahora", "24h", "cerrar", "bloquear", "verificar", "confirmar", "sin delay", "sin acciÃ³n"]
    palabras_urgencia = [p for p in urgencias if p in texto.lower()]
    if len(palabras_urgencia) >= 2:
        alertas.append(f"âš ï¸ Palabras de urgencia: {', '.join(palabras_urgencia)}")

    # 4. Frases demasiado largas/formales
    doc = nlp(texto)
    frases_largas = len([sent for sent in doc.sents if len(sent) > 20])
    if frases_largas > 1:
        alertas.append("âš ï¸ Demasiadas frases complejas â€” poco natural para un humano")

    # 5. DetecciÃ³n de IA
    try:
        ia_pred = detector_ia(texto[:512])
        if ia_pred[0]['label'] == 'LABEL_1' and ia_pred[0]['score'] > 0.7:
            alertas.append("ğŸš¨ ALTA PROBABILIDAD DE SER GENERADO POR IA (como WormGPT)")
    except Exception as e:
        alertas.append("â„¹ï¸ No se pudo analizar con IA (texto muy largo o error tÃ©cnico)")

    # Calcular nivel de riesgo
    score = len(alertas)
    if score >= 4:
        nivel = "ğŸ”´ ALTO RIESGO â€” Â¡Es probable phishing generado por IA!"
        color = "red"
    elif score >= 2:
        nivel = "ğŸŸ¡ MODERADO RIESGO â€” Revisa con cuidado"
        color = "orange"
    else:
        nivel = "ğŸŸ¢ BAJO RIESGO â€” Parece legÃ­timo"
        color = "green"

    return {
        "nivel": nivel,
        "color": color,
        "alertas": alertas,
        "score": score
    }

# --- INTERFAZ STREAMLIT ---
st.set_page_config(page_title="ğŸ›¡ï¸ PhishingGuard", page_icon="ğŸ›¡ï¸", layout="centered")

# --- LOGO ---
st.image("https://i.ibb.co/8YqKJQk/phishingguard-logo.png", width=180)  # Logo pÃºblico desde ImgBB

st.title("ğŸ›¡ï¸ PhishingGuard â€” Detecta mensajes de phishing generados por IA")
st.markdown("""
*Â¿Recibiste un mensaje extraÃ±o? PÃ©galo aquÃ­ y te diremos si fue creado por una IA maliciosa como WormGPT.*  
*(No necesitas ser experto â€” solo pega y presiona "Analizar")*
""")

# Entrada de texto
texto_input = st.text_area(
    "Pega aquÃ­ el mensaje que quieres analizar:",
    height=200,
    placeholder="Ejemplo: 'Estimado cliente, su cuenta serÃ¡ bloqueada en 2 horas. Haga clic aquÃ­: https://secure-bank-login.xyz'"
)

# BotÃ³n de anÃ¡lisis
if st.button("ğŸ” Analizar mensaje"):
    if texto_input.strip():
        with st.spinner("Analizando... Esto puede tomar unos segundos"):
            resultado = analizar_texto(texto_input)
        
        if "error" in resultado:
            st.error(resultado["error"])
        else:
            st.markdown(f"### {resultado['nivel']}")
            st.markdown(f"<span style='color:{resultado['color']}; font-weight:bold;'>{resultado['nivel']}</span>", unsafe_allow_html=True)
            
            if resultado["alertas"]:
                st.subheader("ğŸ“Œ SeÃ±ales detectadas:")
                for alerta in resultado["alertas"]:
                    st.warning(alerta)
            else:
                st.success("âœ… No se encontraron seÃ±ales de riesgo.")
    else:
        st.warning("Por favor ingresa un texto para analizar.")

# InformaciÃ³n adicional
st.markdown("---")
st.markdown("""
### â„¹ï¸ Â¿QuÃ© es esto?
PhishingGuard es una herramienta educativa creada para ayudarte a identificar mensajes falsos generados por inteligencia artificial maliciosa (como **WormGPT**).  
**No es 100% perfecta**, pero detecta patrones comunes usados por ciberdelincuentes.

> âŒ Nunca hagas clic en enlaces sospechosos.  
> âœ… Si dudas, contacta directamente a la empresa por su sitio oficial.

### ğŸ“š Â¿Quieres aprender mÃ¡s?
- [Curso de Ciberseguridad Cisco (gratis)](https://www.netacad.com/courses/cybersecurity)
- [Hugging Face - Modelos de IA Ã©ticos](https://huggingface.co/models)
""")

# Pie de pÃ¡gina
st.markdown("<small>ğŸ› ï¸ Hecho con â¤ï¸ usando Python + Streamlit. No al uso malicioso de la IA.</small>", unsafe_allow_html=True)
